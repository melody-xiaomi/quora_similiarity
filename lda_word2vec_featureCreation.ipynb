{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Load Required Python Libraries\n",
    "##########################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pylev import levenshtein\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import chardet\n",
    "import itertools\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from gensim.models import word2vec, KeyedVectors\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.externals import joblib\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora, models\n",
    "import operator\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Loads in Quora Dataset\n",
    "##########################################\n",
    "#Training Dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "data['question1'] = data['question1'].astype(str)\n",
    "data['question2'] = data['question2'].astype(str)\n",
    "y = data['is_duplicate']\n",
    "df_train = data\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Loads in Quora Test Dataset\n",
    "##########################################\n",
    "#Test Dataset\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "#Replaces np.nan with ''\n",
    "df_test = df_test.replace(np.nan, '', regex=True)\n",
    "\n",
    "#Saves the cleaned test.csv\n",
    "# df_test.to_csv('cleaned_test.csv')\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Initializes variables for Feature Creation\n",
    "##########################################\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "model = KeyedVectors.load(\"300features_10minwords_5context\")\n",
    "\n",
    "def question_to_wordlist(text, remove_stopwords = False):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "    return(words)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Creates 50 LDA topics\n",
    "##########################################\n",
    "q1_list = df_train.question1\n",
    "q2_list = df_train.question2\n",
    "total_questions = list(q1_list) + list(q2_list)\n",
    "\n",
    "#Tokenize each question\n",
    "questions = [question_to_wordlist(question, remove_stopwords = True) for question in total_questions]\n",
    "\n",
    "#Create a Gensim dictionary from the questions\n",
    "dictionary = Dictionary(questions)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "\n",
    "#Convert the dictionary to a Bag of Words corpus for reference\n",
    "corpus = [dictionary.doc2bow(question) for question in questions]\n",
    "\n",
    "#Train LDA model\n",
    "topics=50\n",
    "# lda = models.LdaMulticore(corpus, id2word=dictionary, num_topics=topics, workers=150)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Saves LDA Model\n",
    "##########################################\n",
    "joblib.dump(lda, 'lda_50topics.pkl')\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Loads LDA Model\n",
    "##########################################\n",
    "lda = joblib.load('lda_50topics.pkl')\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Functions for Re-sorting Topic Words\n",
    "##########################################\n",
    "def createTopics(num_topics, num_words, lda_model):\n",
    "    topics = []\n",
    "    words_sorted = []\n",
    "    \n",
    "    for i in tqdm(xrange(0, num_topics)):\n",
    "        words = lda_model.show_topic(i, topn=num_words)\n",
    "        words_list = []\n",
    "        for j in xrange(0, len(words)):\n",
    "            words_list.append(words[j][0])\n",
    "            words_sorted.append(words[j][0])\n",
    "        topics.append(words_list)\n",
    "    \n",
    "    words_resort = [word for word in dictionary.values() if word not in words_sorted]\n",
    "    return topics, words_resort\n",
    "\n",
    "def calcMeanSim(word2vec_model, word, topicWords):\n",
    "    values = []\n",
    "    for i in range(0, len(topicWords)):\n",
    "        try:\n",
    "            values.append(word2vec_model.wv.similarity(word, topicWords[i]))\n",
    "        except:\n",
    "            values.append(0)\n",
    "    mean = np.mean(values)\n",
    "    return mean\n",
    "\n",
    "def categorizeWords(word2vec_model, wordList, topics):\n",
    "    for i in tqdm(xrange(0, len(wordList))):\n",
    "        mean_vals = []\n",
    "        for j in xrange(0, len(topics)):\n",
    "            mean_vals.append(calcMeanSim(word2vec_model, wordList[i], topics[j]))\n",
    "        index, value = max(enumerate(mean_vals), key=operator.itemgetter(1))\n",
    "        topics[index].append(wordList[i])\n",
    "    return topics\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 45.89it/s]\n",
      "100%|██████████| 78331/78331 [4:58:45<00:00,  1.94it/s]   \n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Recreates Topics List using LDA & Word2Vec\n",
    "##########################################\n",
    "topics, words_resort = createTopics(50, 100, lda)\n",
    "new_topics = categorizeWords(model, words_resort, topics)\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_topics.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "# Saves New Topics List\n",
    "##########################################\n",
    "joblib.dump(new_topics, 'new_topics.pkl')\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_topics = joblib.load('new_topics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Create Dataframe with % of 50 topics\n",
    "##########################################\n",
    "topics_percent = []\n",
    "for i in tqdm(xrange(0, len(new_topics))):\n",
    "    topic_curr = []\n",
    "    vec = CountVectorizer(vocabulary=new_topics[i])\n",
    "    data = vec.fit_transform(df_train.question1)\n",
    "    data_array = data.toarray()\n",
    "    \n",
    "    for j in xrange(0, len(data_array)):\n",
    "        topic_curr.append(sum(data_array[j]/float(len(data_array[j])))*100)\n",
    "    topic_curr.append(topics_curr)\n",
    "    \n",
    "copy = topics_percent\n",
    "topics_percent_df = np.reshape(topics_percent, (len(df_train), 50))\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
